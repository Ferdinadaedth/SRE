# 运维知识库

## 1.0.0.服务器的配置

### 1.1.0.linux基础

#### 1.1.1文件系统命令

以下是一些常用且重要的Linux文件系统命令

1. **ls**：列出目录内容。
   
   ```
   ls [options] [directory]
   ```
   
2. **cd**：切换当前工作目录。
   
   ```
   cd [directory]
   ```
   
3. **pwd**：显示当前工作目录的绝对路径。
   ```
   pwd
   ```

4. **mkdir**：创建新目录。
   ```
   mkdir [options] directory_name
   ```

5. **rmdir**：删除空目录。
   ```
   rmdir [options] directory_name
   ```

6. **cp**：复制文件或目录。
   ```
   cp [options] source destination
   ```

7. **mv**：移动文件或目录，也可用于重命名文件。
   ```
   mv [options] source destination
   ```

8. **rm**：删除文件或目录。
   ```
   rm [options] file_name
   ```

9. **touch**：创建新文件或更新文件的访问和修改时间。
   ```
   touch [options] file_name
   ```

10. **cat**：将文件内容打印到终端。
    ```
    cat [options] file_name
    ```

11. **more** 和 **less**：分页查看文件内容。
    ```
    more file_name
    less file_name
    ```

12. **head** 和 **tail**：查看文件的头部和尾部内容。
    ```
    head [options] file_name
    tail [options] file_name
    ```

13. **find**：在文件系统中搜索文件和目录。
    ```
    find [path] [expression]
    ```

14. **grep**：在文件中搜索指定模式。
    ```
    grep [options] pattern [file(s)]
    ```

15. **chmod**：修改文件权限。
    ```
    chmod [options] mode file_name
    ```

16. **chown**：修改文件所有者。
    ```
    chown [options] new_owner file_name
    ```

17. **chgrp**：修改文件所属组。
    ```
    chgrp [options] new_group file_name
    ```

18. **df**：显示文件系统磁盘空间使用情况。
    ```
    df [options]
    ```

19. **du**：显示目录或文件的磁盘使用情况。
    ```
    du [options] [directory/file]
    ```

20. **ln**：创建硬链接或符号链接。
    ```
    ln [options] target link_name
    ```

Linux拥有众多强大的工具和命令来管理文件和目录。在终端中输入命令加上`--help`选项，或查阅相关命令的手册(`man`命令)可获取更详细的帮助信息。例如，要查看`ls`命令的帮助信息，可以输入`man ls`。

#### 1.1.2.文本操作

#### 1.vim

Vim是一款功能强大的文本编辑器,以下是对Vim编辑器的总结：

1. **模式**：
   - 正常模式：默认进入Vim的模式，用于导航、复制、粘贴等操作。
   - 插入模式：用于编辑文本，按下`i`或`Insert`键进入。
   - 命令行模式：用于执行保存、退出等命令，按下`:`键进入。
2. **基本移动**：
   - 使用方向键或`h`（左）、`j`（下）、`k`（上）、`l`（右）进行光标移动。
   - `w`、`b`、`e`分别以单词为单位向前移动。
3. **编辑**：
   - 进入插入模式后，可以直接编辑文本。
   - 使用`dd`删除整行，使用`x`删除当前字符。
   - 使用`yy`复制整行，使用`p`粘贴复制的内容。
4. **保存和退出**：
   - 在正常模式下，使用`:w`保存文件。
   - 使用`:q`退出Vim。
   - 使用`:wq`保存并退出，或者使用`:x`同样效果。
5. **搜索和替换**：
   - 在正常模式下，输入`/`后跟要搜索的内容，按下`Enter`开始搜索。
   - 输入`:s/old/new/g`进行全局替换。
6. **撤销和重做**：
   - 在正常模式下，按下`u`进行撤销，按下`Ctrl + r`进行重做。
7. **分割窗口**：
   - 使用`:split`水平分割窗口，使用`:vsplit`垂直分割窗口。
   - 使用`Ctrl + w`切换窗口。
8. **多标签页**：
   - 使用`:tabnew`新建标签页，使用`:tabnext`和`:tabprev`切换标签页。
   - 使用`:tabclose`关闭当前标签页。
9. **配置和插件**：
   - 配置文件`.vimrc`用于自定义Vim的行为和外观。
   - 可以通过插件管理器（如Vundle、Pathogen或Vim-Plug）安装和管理插件。

#### 2.三剑客（sed，grep，awk）

三剑客是指在Unix/Linux系统中，常用于文本处理的三个强大命令行工具：sed、grep和awk。它们经常一起使用，可以方便地处理和操作文本数据。

1. **sed**：
   - 简介：`sed`是"Stream Editor"的缩写，用于流式文本编辑。
   - 功能：主要用于对文本数据进行转换、替换、删除、插入等操作，它按行处理文本数据，并根据指定的编辑命令进行处理。
   - 使用：`sed 'command' filename`或通过管道`|`传递输入数据。常见的编辑命令有`s`（替换）、`d`（删除）、`p`（打印）、`i`（插入）、`a`（附加）等。

2. **grep**：
   - 简介：`grep`是"Global Regular Expression Print"的缩写，用于在文本中查找匹配指定模式的行。
   - 功能：主要用于搜索和过滤文本数据，根据正则表达式匹配文本中的内容，并将匹配的行输出。
   - 使用：`grep 'pattern' filename`或通过管道`|`传递输入数据。常用选项有`-i`（忽略大小写）、`-r`（递归搜索）、`-v`（反向匹配）等。

3. **awk**：
   - 简介：`awk`是一种处理文本数据的编程语言，也可以作为命令行工具使用。
   - 功能：主要用于分析和处理结构化文本数据，它按行处理数据，并将每行拆分成字段，然后根据指定的脚本进行处理。
   - 使用：`awk 'script' filename`或通过管道`|`传递输入数据。常用的脚本结构由模式（Pattern）和动作（Action）组成，例如`/pattern/ {action}`，其中pattern用于匹配行，action是对匹配行的处理。

三剑客经常一起使用，例如，可以使用grep筛选文本数据的行，然后通过sed进行编辑和转换，最后使用awk进行数据分析和提取。它们的强大组合为用户提供了高效处理文本数据的能力，尤其在批量处理日志文件、数据清洗、数据提取等任务中非常实用。

#### 3.head和tail

`head`和`tail`是两个常用的命令行工具，用于查看文件的头部和尾部内容。它们在处理大型文件时特别有用，因为可以快速预览文件的部分内容而无需打开整个文件。

1. **head**：
   - 简介：`head`命令用于显示文件的开头部分，默认显示文件的前10行。
   - 使用：`head [options] [filename]`。可以通过`-n`选项指定显示的行数，例如`head -n 20 file.txt`将显示文件`file.txt`的前20行内容。

2. **tail**：
   - 简介：`tail`命令用于显示文件的末尾部分，默认显示文件的最后10行。
   - 使用：`tail [options] [filename]`。可以通过`-n`选项指定显示的行数，例如`tail -n 15 file.txt`将显示文件`file.txt`的最后15行内容。
   - 实时追踪：使用`tail -f [filename]`命令可以实时追踪文件的变化，例如查看日志文件时，会持续输出新添加的日志。

这两个命令在日常文件查看和快速预览时非常有用。常见用例包括查看日志文件的最新记录、预览配置文件的头部内容等。当需要查看文件的特定部分时，可以通过`-n`选项指定显示的行数。同时，`tail -f`命令可以帮助实时追踪日志文件的变化，非常适合在调试和监控中使用。

### 1.1.3.shell基础

Shell是一种命令行解释器，它允许用户与操作系统进行交互，并通过输入命令来执行各种任务。以下是Shell基础的总结：

1. **命令行界面**：
   - Shell提供了一个命令行界面（也称为终端或控制台），用户可以在其中输入命令并接收输出。
   - 命令行由提示符表示，通常是一个特殊字符（如`$`或`#`）。

2. **命令和选项**：
   - 用户可以在Shell中输入命令来执行各种操作，例如文件操作、进程管理、文本处理等。
   - 命令可以带有选项和参数，选项通常用短横线（`-`）前缀，用于修改命令的行为。

3. **文件路径**：
   - Shell使用文件路径来定位文件和目录。绝对路径从根目录开始，相对路径从当前工作目录开始。
   - 特殊路径符号：`~`表示用户主目录，`.`表示当前目录，`..`表示上一级目录。

4. **通配符**：
   - Shell支持通配符用于匹配文件名。例如，`*`匹配零个或多个字符，`?`匹配单个字符，`[...]`匹配指定范围内的字符。

5. **变量**：
   - 在Shell中，变量用于存储数据。变量名通常使用大写字母，可以使用等号（`=`）进行赋值和引用变量的值。

6. **流程控制**：
   - Shell支持流程控制结构，如条件语句（if-then-else）、循环（for、while）、函数等，以便编写更复杂的脚本。

7. **重定向和管道**：
   - 通过重定向，可以将命令的输出重定向到文件（`>`将输出覆盖，`>>`将输出追加）或从文件中读取输入（`<`）。
   - 通过管道（`|`），可以将一个命令的输出作为另一个命令的输入，以实现数据流的串联。

8. **常用Shell**：
   - 在Linux和Unix系统中，常用的Shell包括Bash（Bourne Again SHell，大多数Linux默认Shell）、sh（Bourne Shell）、zsh（Z Shell）等。

9. **脚本编写**：
   - 用户可以编写Shell脚本，即一系列Shell命令的文本文件。脚本可以保存并重复执行一系列任务。

10. **帮助和手册**：
    - 用户可以使用`man`命令查看命令的手册页，了解命令的使用方法和选项。
    - 使用`--help`选项或`-h`选项通常也可以获得命令的简要帮助信息。

Shell是Linux和Unix系统中强大且灵活的工具，掌握Shell基础对于在命令行环境下高效地进行系统管理和任务处理至关重要。

### 1.1.4.linux系统下的磁盘的格式化/分区/挂载

在Linux系统下，磁盘的格式化、分区和挂载是磁盘管理的重要操作。下面对它们进行简要总结：

1. **磁盘格式化：** 格式化是指在磁盘上创建文件系统，以便操作系统可以将数据存储在其中。在格式化之前，磁盘通常是一个空的、未分区的块设备。格式化操作将为磁盘创建文件系统结构，例如ext4、XFS等，使其能够存储文件和目录。

   格式化命令：`mkfs` + 文件系统类型 + 设备路径

   例如：`mkfs.ext4 /dev/sdb1` 将设备`/dev/sdb1`格式化为ext4文件系统。

2. **磁盘分区：** 分区是将一个大的磁盘划分为多个较小的逻辑分区的过程。每个分区都会有自己的文件系统，并且可以独立使用。磁盘分区的目的是更好地组织数据、提高性能和管理存储空间。

   磁盘分区命令：使用工具如`fdisk`、`parted`等进行分区操作。

   例如：`fdisk /dev/sdb` 进入fdisk工具对设备`/dev/sdb`进行分区。

3. **磁盘挂载：** 挂载是指将文件系统附加到Linux文件系统层次结构中的指定目录，以便用户和应用程序可以访问该文件系统中的数据。在Linux中，磁盘通常被挂载到`/mnt`、`/media`或`/home`等目录下。

   磁盘挂载命令：`mount` + 设备路径 + 挂载点

   例如：`mount /dev/sdb1 /mnt/data` 将设备`/dev/sdb1`挂载到`/mnt/data`目录。

   可以使用`/etc/fstab`文件来设置开机自动挂载，避免每次重启时手动挂载。

总结：磁盘格式化、分区和挂载是Linux系统中管理磁盘空间的基本操作。格式化为磁盘创建文件系统，分区将磁盘划分为多个逻辑区域，挂载将文件系统连接到指定目录，使其可被访问。这些操作是在管理磁盘空间、存储和访问文件时非常重要的步骤。

### 1.1.5.linux编写服务

在Linux中编写服务通常涉及创建一个守护进程或系统服务，它可以在后台运行，并且可以自动在系统启动时启动。以下是编写Linux服务的一般步骤和注意事项：

1. **编写服务代码：** 首先编写服务的代码。服务代码应该是一个长期运行的进程，并且通常需要实现一些守护进程的特性，比如正确处理信号、处理日志输出等。

2. **设置服务配置：** 在编写服务之前，需要决定服务的配置信息，例如它应该监听哪个端口，配置文件的位置等。这些配置应该被硬编码在服务代码中，或者更好的方式是将它们存储在配置文件中，以便在需要时进行修改。

3. **编写服务脚本：** 为了方便管理和操作服务，通常会编写一个启动、停止、重启和查看状态的脚本。这些脚本可以是Bash脚本或其他脚本语言编写的，它们可以调用编写的服务代码，并提供简单的接口用于管理服务。

4. **创建服务文件：** 在Linux中，服务通常被定义为一个Systemd单元（unit）。需要编写一个`.service`文件来描述服务。该文件包含服务的元数据，包括服务的名称、描述、启动命令、依赖关系等。

5. **配置自动启动：** 在创建了`.service`文件后，可以通过Systemd将服务配置为在系统启动时自动启动。使用`systemctl enable`命令启用服务。

6. **测试和调试：** 在部署服务之前，确保服务在测试环境中运行正常。可以通过日志输出和系统日志来调试服务代码，并确保它能够正确地响应各种情况和错误。

7. **部署服务：** 最后，将服务部署到目标Linux系统上。将服务的二进制文件和配置文件复制到适当的位置，一般来说ubuntu在/lib/systemd/system/目录下,并启动服务。并可以用systemctl status查看状态,使用脚本来管理服务的启动、停止和重启操作。

总结：编写Linux服务涉及编写服务代码、创建服务脚本和`.service`文件，配置自动启动，并确保服务在测试环境中正常运行。通过Systemd和相关脚本，可以方便地管理和部署服务，让它在系统启动时自动运行，并且能够长期稳定地在后台执行所需的任务。

### 1.1.6.ssh

#### 1.配置sshd服务

1. **备份配置文件：** 在进行任何配置更改之前，建议先备份SSH服务的配置文件，以防出现问题。SSH服务的配置文件通常是`/etc/ssh/sshd_config`。

2. **编辑sshd_config文件：** 使用文本编辑器（如`vi`或`nano`）打开SSH服务的配置文件`/etc/ssh/sshd_config`。

3. **查找并修改PermitRootLogin：** 在`sshd_config`文件中找到名为`PermitRootLogin`的配置项。通常，默认值为`prohibit-password`或`yes`，表示不允许root登录。将其修改为`yes`，即允许root登录。

   例如：`PermitRootLogin yes`

4. **保存配置文件：** 保存`sshd_config`文件并关闭文本编辑器。

5. **重启SSH服务：** 使用适当的命令（通常是`systemctl`）重启SSH服务，以使配置更改生效。

   例如：`sudo systemctl restart sshd`

#### 2.学会使用和管理ssh公私钥

1. **生成SSH公私钥对：** 使用`ssh-keygen`命令生成SSH公私钥对。默认情况下，它会在用户主目录下的`.ssh`文件夹中生成`id_rsa`（私钥）和`id_rsa.pub`（公钥）文件。

2. **传输公钥到远程服务器：** 如果希望使用SSH公钥登录远程服务器，需要将本地生成的公钥文件内容复制到远程服务器的`~/.ssh/authorized_keys`文件中。

   例如：`ssh-copy-id username@remote_server`

3. **设置SSH配置：** 可以在SSH客户端和服务器端的配置文件中进行一些设置，以提高安全性和便捷性。客户端配置文件通常是`~/.ssh/config`，服务器端配置文件通常是`/etc/ssh/sshd_config`。

4. **密码认证和密钥认证：** 默认情况下，SSH同时允许密码认证和密钥认证。为了提高安全性，可以在服务器端禁用密码认证，仅允许密钥认证。

5. **密钥保护：** 为了保护私钥，可以设置密钥的密码。这样每次使用私钥时，都需要输入密码进行解锁。

6. **密钥管理：** 可以在本地系统中管理和维护多个SSH密钥对，以便访问多个远程服务器或服务。

7. **撤销和更换密钥：** 如果认为私钥可能已泄漏或不再安全，应该撤销并生成新的密钥对。确保删除旧的公钥并将新公钥复制到远程服务器。

8. **SSH代理：** SSH代理允许在本地计算机上管理多个SSH私钥，而不需要每次登录时手动输入密码。

### 1.1.7.命令后台运行

1. **使用`&`符号：** 在Linux命令行中，在命令末尾加上`&`符号可以让命令在后台运行。例如：`command &`，这将使`command`在后台运行。

2. **使用`nohup`命令：** `nohup`命令可以使命令在后台运行，并忽略挂断信号（SIGHUP）。这样即使关闭终端，命令也会继续运行。例如：`nohup command &`。

3. **使用`screen`命令：** `screen`是一个终端多路复用器，它允许在单个终端会话中创建多个窗口，并在其中运行不同的命令。可以使用以下步骤在`screen`中后台运行命令：

   - 打开`screen`会话：`screen`
   - 运行命令：`command`
   - 按下`Ctrl + A`，然后按下`d`，将`screen`会话切换到后台运行

   要重新连接到`screen`会话，可以使用`screen -r`命令。

4. **编写系统服务：** 对于需要长期运行且需要在系统启动时自动启动的任务，可以编写系统服务。使用`systemd`或其他系统初始化工具来创建服务，并将命令配置为在后台运行。服务配置通常存储在`/etc/systemd/system/`目录中。

### 1.2.0.进入bios以及配置

执行`sudo systemctl reboot --firmware-setup`，重启直接不进入系统，而进入bios。

**BIOS配置：** 一旦进入BIOS设置界面，可以使用键盘上的方向键和回车键来导航和选择不同的配置选项。具体的配置选项和菜单布局可能因服务器型号和BIOS版本而异。

常见的BIOS配置选项包括：

- **启动顺序（Boot Order）：** 设置服务器启动时读取的设备顺序，例如硬盘阵列、光驱、USB设备等。
- **日期和时间（Date and Time）：** 设置服务器的系统日期和时间。
- **硬件设置：** 可能包括处理器、内存、硬盘、RAID配置、显卡等设置，例如启用或禁用特定设备、设置内存频率等。
- **安全设置：** 可能包括设置密码、开启安全启动（Secure Boot）等。
- **电源管理：** 设置服务器的节能和电源管理选项。

### 1.3.0.虚拟机配置-pve

1. **登录PVE Web界面：** 打开浏览器，输入PVE服务器的IP地址或域名，然后使用管理员账号登录PVE Web界面。
2. **创建虚拟机（VM）：** 在PVE Web界面中，可以通过"创建虚拟机"向导来创建新的虚拟机。可以选择虚拟机的操作系统、资源配置、硬盘大小等。
3. **创建容器（LXC）：** PVE支持Linux容器（LXC），可以创建LXC容器来运行轻量级的应用。通过"创建容器"向导，可以选择容器的操作系统模板、网络配置等。
4. **启动/停止/重启虚拟机或容器：** 在PVE Web界面中，可以对虚拟机和容器进行启动、停止和重启操作。右键点击虚拟机或容器，选择相应的操作。
5. **备份和恢复虚拟机或容器：** PVE支持虚拟机和容器的快照和备份功能。可以创建虚拟机或容器的快照，也可以备份整个虚拟机或容器的配置和磁盘数据。
6. **创建存储：** PVE支持多种存储类型，例如本地存储、NFS、iSCSI等。可以通过"创建存储"来添加新的存储，并将其挂载到虚拟机或容器上。
7. **创建网络：** PVE支持多种网络类型，例如Linux Bridge、Open vSwitch等。可以通过"创建网络"来添加新的网络，将虚拟机或容器连接到网络。
8. **资源管理：** 在PVE Web界面中，可以监控虚拟机和容器的资源使用情况，包括CPU、内存、磁盘和网络等。
9. **节点管理：** PVE支持多节点管理，可以添加其他PVE节点，并进行集群管理和迁移虚拟机。
10. **集群HA和备份：** PVE支持高可用（HA）配置，可以确保虚拟机在节点故障时自动迁移到其他节点。此外，可以设置定期备份虚拟机和容器数据。
11. **SSH访问：** 如果需要进行高级配置或故障排除，可以通过SSH访问PVE服务器。

### 1.4.0.网络配置

#### 1.4.1路由表和nginx配置

可以理解和编写路由表和Nginx配置是非常有用的技能，特别对于网络和Web服务器的管理和配置。以下是简要解释和示例：

1. **路由表：**
   路由表是用于确定数据包在网络中传输的路径的表格。它包含目标网络、下一跳路由器和接口等信息。路由表用于决定数据包应该通过哪个网关发送，以便到达其目标地址。在Linux系统中，可以使用`ip route`命令查看和配置路由表。

   示例：
   ```
   Destination     Gateway         Genmask         Flags Metric Ref    Use Iface
   192.168.1.0     0.0.0.0         255.255.255.0   U     0      0        0 eth0
   default         192.168.1.1     0.0.0.0         UG    100    0        0 eth0
   ```
   在上面的示例中，第一行表示将数据包发送到目标网络192.168.1.0/24，通过接口eth0进行传输。第二行表示默认路由，将所有未知目标发送到网关192.168.1.1。

2. **Nginx配置：**
   Nginx是一款高性能的Web服务器和反向代理服务器。Nginx的配置文件位于`/etc/nginx/nginx.conf`或`/etc/nginx/sites-available/`目录下。可以使用文本编辑器（如vi或nano）来编辑Nginx配置。

   示例：
   ```nginx
   server {
       listen 80;
       server_name example.com;
       root /var/www/html;
   
       location / {
           try_files $uri $uri/ =404;
       }
   }
   ```
   在上面的示例中，配置了一个简单的Nginx虚拟主机，监听80端口，使用example.com为域名，网站文件存放在`/var/www/html`目录下。当访问该虚拟主机时，Nginx会尝试匹配请求的URI，如果找不到对应的文件或目录，则返回404错误。


#### 1.4.2配置域名解析和DDNS服务：

1. **购买域名：** 首先，需要购买一个域名，可以通过各大域名注册商进行购买。选择一个合适的域名，并进行注册,注册后，一般来说在云厂商就可以直接配置域名解析。
2. **配置DDNS服务：** 如果公网IP地址是动态分配的（例如家庭网络的公网IP可能会随着重启或重新连接而变化），则需要配置DDNS服务，以便在IP地址变化时自动更新域名解析。
   - 在DNS服务提供商的控制面板中，查找并启用DDNS服务。
   - 在路由器或服务器上配置DDNS客户端，通常可以在网络设置或DDNS选项中找到。输入在DNS服务提供商注册的DDNS账号和域名，设置更新频率等。
   - DDNS客户端会定期检测公网IP地址的变化，并在IP地址发生变化时自动更新域名解析。
   - DDNS-go,一个开源软件，可以直接在[Releases · jeessy2/ddns-go (github.com)](https://github.com/jeessy2/ddns-go/releases)上下载使用

#### 1.4.3配置服务器网卡

配置服务器网卡是将服务器连接到网络的重要步骤。以下是学会配置服务器网卡的一般步骤：

1. **查看网络接口：** 在服务器上打开终端或SSH会话，并运行以下命令来查看当前可用的网络接口：
   ```
   ip addr show
   ```
   或
   ```
   ifconfig
   ```
   这将列出服务器上所有的网络接口，包括以太网接口（通常命名为ethX，X是数字）和无线接口（通常命名为wlanX）。

2. **编辑配置文件：** 确定要配置的网络接口后，使用文本编辑器（如vi或nano）打开网络配置文件进行编辑。在大多数Linux系统中，网络配置文件位于`/etc/network/interfaces`或`/etc/sysconfig/network-scripts/ifcfg-ethX`，具体位置可能因Linux发行版而异。

3. **配置静态IP地址：** 如果的服务器需要使用静态IP地址，请在配置文件中添加以下内容（以Ubuntu为例）：
   
   ```plaintext
   auto eth0
   iface eth0 inet static
   address 192.168.1.100       # 服务器IP地址
   netmask 255.255.255.0       # 子网掩码
   gateway 192.168.1.1         # 默认网关
   dns-nameservers 8.8.8.8     # DNS服务器（可选，使用Google DNS作为示例）
   ```
   替换上述示例中的IP地址、子网掩码、默认网关和DNS服务器地址为的网络设置。
   
4. **配置动态IP地址（DHCP）：** 如果服务器需要使用动态IP地址（由DHCP服务器分配），需要在配置文件中添加以下内容（以Ubuntu为例）：
   
   ```plaintext
   auto eth0
   iface eth0 inet dhcp
   ```
   这将使服务器从DHCP服务器获取IP地址和其他网络配置信息。
   
5. **重启网络服务：** 保存配置文件后，使用以下命令重启网络服务以使更改生效（以Ubuntu为例）：
   ```plaintext
   sudo service networking restart
   ```
   或
   ```plaintext
   sudo systemctl restart networking
   ```

6. **验证网络连接：** 使用以下命令来验证服务器的网络连接是否正常：
   ```plaintext
   ip addr
   ```
   或
   ```plaintext
   ifconfig
   ```
   确保服务器的网络接口已获得正确的IP地址和网络配置。

### 1.4.4.frp

学会使用内网穿透工具（如frp）可以帮助在公网上访问内部网络中的服务或设备，从而实现远程访问和管理。以下是使用frp等内网穿透工具的基本步骤：

1. **安装frp：** 首先，需要在服务器和客户端上安装frp。可以从frp的官方网站或从[Releases · fatedier/frp (github.com)](https://github.com/fatedier/frp/releases)下载适用于对应操作系统的版本，并按照安装说明进行安装。

2. **配置frp服务器：** 在服务器上配置frp服务器。编辑frps.ini配置文件，设置服务器的监听端口和通信密码等参数。

   示例frps.ini配置文件：
   ```ini
   [common]
   bind_port = 7000        # 监听端口，用于接收客户端连接
   dashboard_port = 7500   # 可选，用于web管理界面访问
   token = your_password   # 通信密码，用于认证客户端
   ```
   保存配置文件后，运行frps服务：`nohup ./frps -c frps.ini >/dev/null 2>&1 &`

3. **配置frp客户端：** 在需要被穿透的内网服务器或设备上配置frp客户端。编辑frpc.ini配置文件，设置客户端连接的服务器地址和通信密码等参数。

   示例frpc.ini配置文件：
   ```ini
   [common]
   server_addr = your_server_ip     # 服务器地址
   server_port = 7000               # 服务器端口，与frps.ini中配置的一致
   token = your_password            # 通信密码，与frps.ini中配置的一致

   [ssh]
   type = tcp
   local_ip = 127.0.0.1
   local_port = 22                  # 需要穿透的内网服务端口
   remote_port = 6000               # 公网访问时的端口
   ```
   在上面的示例中，配置了一个用于SSH的内网穿透规则。客户端连接服务器后，服务器将转发公网访问的请求到内网服务器的22端口（SSH端口）。

4. **运行frp客户端：** 保存配置文件后，运行frpc服务：`nohup ./frpc -c ./frpc.ini >/dev/null 2>&1 &`,当然，frp服务建议写成servie，方便查看状态以及启动关闭

5. **验证穿透效果：** 确保frp客户端已成功连接到frp服务器。然后尝试从公网访问frp服务器的IP和指定的端口，确认是否成功访问到内网服务器或设备的服务。

### 1.4.5.nginx

**安装Nginx：** 首先，在服务器上安装了Nginx。可以使用适用于操作系统的软件包管理器来安装Nginx。

#### 1.正向代理

1. **配置正向代理：** 编辑Nginx配置文件（通常是`/etc/nginx/nginx.conf`或`/etc/nginx/conf.d/default.conf`），添加正向代理配置。

   示例配置：

   ```
   nginxCopy codeserver {
       listen 80;    # 监听端口
       server_name _;   # 占位符，匹配任意域名
   
       location / {
           proxy_pass http://target_server;    # 目标服务器地址
           proxy_set_header Host $host;        # 设置代理请求的Host头部
           proxy_set_header X-Real-IP $remote_addr;    # 设置代理请求的真实客户端IP
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;   # 设置代理请求的客户端IP列表
       }
   }
   ```

   将`http://target_server`替换为想要代理的目标服务器的地址。可以使用IP地址或域名，如果使用域名，确保DNS解析能够正确解析到目标服务器。

2. **保存配置文件并重启Nginx：** 保存配置文件后，检查Nginx配置是否正确（使用`nginx -t`命令），然后重新加载Nginx服务以使配置生效（使用`nginx -s reload`命令）。

3. **测试正向代理：** 配置完成后，可以使用客户端（浏览器或命令行工具）发送请求到Nginx服务器，Nginx将会将请求转发到目标服务器，并将目标服务器的响应返回给客户端。

   #### 2.反向代理

1. **配置反向代理和负载均衡：** 编辑Nginx配置文件（通常是`/etc/nginx/nginx.conf`或`/etc/nginx/conf.d/default.conf`），添加反向代理和负载均衡配置。

   示例配置：

   ```
   nginxCopy codeupstream backend_servers {
       server 192.168.1.100:8080;
       server 192.168.1.101:8080;
       server 192.168.1.102:8080;
   }
   
   server {
       listen 80;    # 监听端口
       server_name example.com;   # 替换为域名
   
       location / {
           proxy_pass http://backend_servers;    # 反向代理和负载均衡的目标服务器组
           proxy_set_header Host $host;          # 设置代理请求的Host头部
           proxy_set_header X-Real-IP $remote_addr;    # 设置代理请求的真实客户端IP
           proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;   # 设置代理请求的客户端IP列表
       }
   }
   ```

   在上面的示例中，我们定义了一个名为`backend_servers`的后端服务器组，其中包含三个后端服务器的地址和端口。在`server`块中，我们配置了反向代理和负载均衡，将客户端的请求转发到`backend_servers`组中的后端服务器，并设置了代理请求的头部信息。

2. **保存配置文件并重启Nginx：** 保存配置文件后，检查Nginx配置是否正确（使用`nginx -t`命令），然后重新加载Nginx服务以使配置生效（使用`nginx -s reload`命令）。

3. **测试反向代理和负载均衡：** 配置完成后，可以使用客户端（浏览器或命令行工具）发送请求到Nginx服务器（例如`http://example.com`），Nginx将会将请求转发到后端服务器组中的某个后端服务器，并将后端服务器的响应返回给客户端。

### 1.4.6.nginx配置HTTPS/ssl流量卸载/强制HTTPS

配置Nginx以实现HTTPS和SSL流量卸载以及强制HTTPS需要进行一系列步骤。以下是基本的配置步骤：

1. **安装SSL证书：** 首先，需要获取有效的SSL证书，可以通过购买或申请免费的证书。证书通常包括公钥和私钥。确保将证书和私钥文件放置在安全的位置，并确保Nginx能够访问它们。

2. **配置HTTPS服务器：** 编辑Nginx配置文件（通常是`/etc/nginx/nginx.conf`或`/etc/nginx/conf.d/default.conf`），添加HTTPS服务器配置。

   示例配置：
   ```nginx
   server {
       listen 443 ssl;   # 监听HTTPS默认端口，并启用SSL
       server_name example.com;   # 替换为域名

       ssl_certificate /path/to/your_certificate.crt;   # 指定SSL证书路径
       ssl_certificate_key /path/to/your_private_key.key;   # 指定私钥文件路径

       location / {
           # 添加的其他代理或反向代理配置
       }
   }
   ```
   将`example.com`替换为域名，`/path/to/your_certificate.crt`和`/path/to/your_private_key.key`替换为实际证书和私钥的文件路径。

3. **配置SSL流量卸载：** Nginx会将HTTPS请求解密，然后将解密后的明文请求转发到后端服务器。确保后端服务器配置是使用普通HTTP而不是HTTPS。

4. **配置强制HTTPS：** 如果想强制所有请求都使用HTTPS，可以添加HTTP到HTTPS的重定向配置。

   示例配置：
   ```nginx
   server {
       listen 80;   # 监听HTTP默认端口
       server_name example.com;   # 替换为域名

       location / {
           return 301 https://$host$request_uri;   # 重定向到HTTPS
       }
   }
   ```

5. **保存配置文件并重启Nginx：** 保存配置文件后，检查Nginx配置是否正确（使用`nginx -t`命令），然后重新加载Nginx服务以使配置生效（使用`nginx -s reload`命令）。

配置完成后，Nginx将通过443端口提供HTTPS服务，并通过80端口对所有HTTP请求进行重定向到HTTPS。所有HTTPS请求将被解密并转发到后端服务器，而所有HTTP请求将被重定向到HTTPS。请确保SSL证书是有效的，并定期更新证书以保持安全性。

## 2.0.0云平台资源运维

### 2.1.0域名管理

在域名管理中，域名解析是将域名转换为IP地址的过程，使得用户可以通过易记的域名访问网站，而不需要记住复杂的IP地址。常见的域名解析及其含义包括：

1. **A记录（Address Record）：** 将域名解析为IPv4地址。A记录用于将域名映射到IPv4地址，使得用户可以通过域名访问网站或服务。

2. **AAAA记录（IPv6 Address Record）：** 将域名解析为IPv6地址。AAAA记录用于将域名映射到IPv6地址，适用于IPv6网络环境。

3. **CNAME记录（Canonical Name Record）：** 将域名解析为另一个域名。CNAME记录允许将一个域名的解析指向另一个域名，用于简化配置和管理，也称为域名别名。

4. **MX记录（Mail Exchange Record）：** 指定邮件服务器的域名。MX记录用于指定接收该域名下邮件的邮件服务器，即邮件交换服务器。

5. **TXT记录（Text Record）：** 存储文本信息。TXT记录用于存储任意文本信息，常用于验证域名所有权、SPF（发件人策略框架）设置和DKIM（域键标识邮件）配置等。

6. **NS记录（Name Server Record）：** 指定域名服务器的域名。NS记录用于指定管理该域名解析的域名服务器，即域名服务器记录。

7. **SOA记录（Start of Authority Record）：** 定义域名的管理参数。SOA记录包含有关域名区域的管理信息，如刷新时间、过期时间等。

8. **SRV记录（Service Record）：** 指定服务的位置。SRV记录用于指定提供特定服务的服务器的域名、端口和优先级。

这些常见的域名解析记录在域名管理界面中可以进行配置和修改。通过适当配置这些解析记录，可以将域名正确地解析到相应的IP地址和服务器，从而使网站或服务能够正常访问和运行。

### 2.2.0 云储存

云存储是一种基于云计算技术的数据存储服务，通过将数据存储在云服务提供商的服务器上，用户可以随时随地访问和管理自己的数据。云存储提供了高可用性、可扩展性、数据备份和灾难恢复等功能，广泛应用于个人用户和企业组织。

#### 2.2.1对象储存

对象存储是云存储中的一种重要形式，它以对象为基本存储单元，每个对象包含数据、元数据和唯一的标识符。对象存储不像传统的文件系统，它不需要在层次结构中建立目录和文件夹，而是直接以键值对（Key-Value）的方式存储和检索数据。对象存储通常采用分布式架构，在多个节点上存储数据，从而实现高可用性和容错性。

对象存储的特点包括：

1. **无结构化：** 对象存储不需要预先建立目录结构，每个对象都有唯一的标识符，可以通过标识符直接访问。
2. **无限扩展性：** 对象存储可以轻松扩展以适应大规模数据的存储需求，无需关心底层硬件和存储设备。
3. **高可靠性：** 对象存储使用冗余备份和数据分布策略，确保数据的高可靠性和持久性。
4. **并发访问：** 对象存储支持多用户的并发读写访问，适合处理大量请求和数据访问。
5. **数据安全：** 对象存储提供数据加密和访问控制等安全机制，确保数据的安全性和隐私保护。
6. **低延迟：** 对象存储通常具有较低的数据读写延迟，适合处理实时数据和高并发请求。

### 2.3.0.CDN加速

CDN（Content Delivery Network）是一种分布式存储和传输技术，用于提高网站内容的传输速度和性能。CDN通过在全球各地建立节点服务器来缓存和分发网站的静态资源，如图片、CSS、JavaScript、视频和其他静态文件。当用户请求访问网站时，CDN会根据用户的地理位置选择最近的节点服务器，从而实现快速的内容传输和加载，提高用户体验。

CDN加速的主要优势包括：

1. **降低网络延迟：** 将内容缓存到离用户更近的节点服务器上，减少数据传输的距离，从而降低网络延迟，加快网页加载速度。
2. **减轻源服务器负载：** CDN会将部分请求转发到缓存节点服务器，减轻源服务器的负载压力，提高网站的并发处理能力。
3. **提高可靠性和稳定性：** CDN在全球多个地点部署了节点服务器，一旦源服务器发生故障，CDN会自动切换到其他节点，保证网站的可靠性和稳定性。
4. **节约带宽成本：** CDN可以节约源服务器的带宽成本，因为大部分请求会由缓存节点服务器处理，只有少部分请求需要转发到源服务器。
5. **全球覆盖：** CDN的节点服务器遍布全球各个地区，可以为用户提供更快、更稳定的访问体验。

### 2.4.0.自动化证书签发

常用的自动化证书签发工具和协议包括：

1. **ACME协议：** ACME（Automatic Certificate Management Environment）是一个由Let's Encrypt（免费SSL证书颁发机构）提出的自动化证书签发协议。ACME协议使用API方式与CA通信，可以通过自动化工具（如Certbot）来自动申请、颁发和更新SSL证书。
2. **Certbot：** Certbot是一个开源的ACME客户端工具，可以与Let's Encrypt配合使用，实现SSL证书的自动化签发和更新。Certbot支持多种Web服务器和操作系统。
3. **ACME.sh：** ACME.sh是另一个ACME客户端工具，支持多种操作系统和Web服务器，可以用于自动化地申请和更新SSL证书。
4. **Nginx、Apache插件：** Nginx和Apache等Web服务器通常提供了自动化证书签发的插件，这些插件可以方便地与ACME协议集成，实现SSL证书的自动化管理。

自动化证书签发的流程通常包括以下步骤：

1. 安装自动化证书签发工具（如Certbot）并配置。
2. 配置Web服务器以支持SSL，并将证书签发工具与Web服务器集成。
3. 运行证书签发工具，它会自动生成证书请求，向CA提交请求并验证域名所有权。
4. CA颁发证书后，签发工具会将证书配置到Web服务器中，使其生效。
5. 设置证书自动更新，以确保证书的有效性。

## 3.0.0平台集群运维

### 3.1.0.k8s基础

#### 3.1.1.k8s架构/概念

Kubernetes（通常缩写为K8s）是一个开源的容器编排平台，用于自动化容器的部署、扩展和管理。它可以帮助您简化应用程序部署、管理和自动化的过程。以下是Kubernetes的一些基本概念和架构组件：

1. 节点（Nodes）：
   节点是Kubernetes集群中的工作机器，它可以是物理计算机或虚拟机。每个节点负责运行容器，并由Master节点进行管理。

2. 主节点（Master Nodes）：
   主节点是Kubernetes集群的控制平面，负责整个集群的管理和决策。它包含以下主要组件：
   - Kubernetes API Server：集群的前端接口，用于处理所有外部请求，包括管理、监控和部署。
   - Scheduler：负责监视新创建的Pod，并将它们分配到合适的节点上运行。
   - Controller Manager：包含多个控制器，负责处理集群的状态和维护。
   - etcd：一个高可用的键值存储系统，用于保存整个集群的状态信息。

3. Pod：
   Pod是Kubernetes中最小的部署单元，可以包含一个或多个紧密关联的容器。Pod中的容器共享网络命名空间和存储，它们可以在同一主机上运行，相互之间通过localhost进行通信。

4. 容器：
   容器是应用程序的打包格式，包含所有运行时所需的代码、运行时、系统工具、库以及设置。Kubernetes使用容器技术（如Docker）来部署和管理应用程序。

5. 控制器（Controllers）：
   控制器用于确保在Kubernetes集群中的期望状态。常见的控制器包括：
   - ReplicaSet：确保指定数量的Pod副本在集群中运行。
   - Deployment：管理Pod副本集，并支持滚动更新。
   - StatefulSet：用于有状态应用程序，如数据库。
   - DaemonSet：在每个节点上运行一个Pod副本。
   - Job：用于运行一次性任务或批处理作业。

6. 服务（Services）：
   服务是Pod的稳定网络终结点，它们提供了一个固定的IP地址和DNS名称，用于让其他应用程序可以轻松地访问它们。

7. 命名空间（Namespaces）：
   命名空间是用来在集群中划分资源的方式，它可以帮助组织和隔离不同团队或项目的资源。

8. 存储卷（Volumes）：
   存储卷是用于将持久化数据存储在Pod中的一种抽象概念。它可以将底层存储系统挂载到容器中，使数据在容器重启时不会丢失。

9. 标签（Labels）和选择器（Selectors）：
   标签是键值对，用于标识Pod或其他Kubernetes对象。选择器允许您按标签选择一组对象，并对它们执行操作，如部署、扩展或删除。

### 3.1.2.常用的kubectl命令

`kubectl` 是与 Kubernetes 集群交互的命令行工具。以下是一些常用的 `kubectl` 命令：

1. 查看集群信息：
   - `kubectl cluster-info`：显示集群的连接信息。
   - `kubectl version`：查看 Kubernetes 客户端和服务器的版本信息。

2. 获取资源列表：
   - `kubectl get pods`：显示当前命名空间下的所有 Pod。
   - `kubectl get deployments`：显示当前命名空间下的所有部署。
   - `kubectl get services`：显示当前命名空间下的所有服务。
   - `kubectl get nodes`：显示集群中所有节点的状态。

3. 创建和管理资源：
   - `kubectl create`：通过文件或标准输入创建资源。
   - `kubectl apply`：通过文件或标准输入创建或更新资源。
   - `kubectl delete`：通过文件、标签选择器或资源名称删除资源。

4. 查看资源详细信息：
   - `kubectl describe pod <pod-name>`：显示特定 Pod 的详细信息。
   - `kubectl describe deployment <deployment-name>`：显示特定部署的详细信息。

5. 查看资源日志：
   - `kubectl logs <pod-name>`：查看特定 Pod 的日志。

6. 执行命令：
   - `kubectl exec -it <pod-name> -- <command>`：在特定 Pod 中执行命令。

7. 进入 Pod：
   - `kubectl exec -it <pod-name> -- /bin/bash`：进入特定 Pod 的交互式终端。

8. 扩展和缩放：
   - `kubectl scale deployment <deployment-name> --replicas=<num>`：扩展或缩小部署的副本数。

9. 更新资源：
   - `kubectl edit <resource-type> <resource-name>`：通过编辑文件来更新资源。
   - `kubectl set image deployment/<deployment-name> <container-name>=<new-image>`：更新部署的容器镜像版本。

10. 调试和故障排除：
    - `kubectl describe`：查看资源的详细信息，帮助排查问题。
    - `kubectl logs`：查看 Pod 日志，找出问题所在。
    - `kubectl get events`：查看集群事件，以便了解发生的情况。

### 3.1.3.编写一般项目的yaml文件

编写 Kubernetes 中的 YAML 文件可以使用文本编辑器，例如 Visual Studio Code 或 Notepad++。以下是一般项目中常用的 YAML 文件示例：

### 1. 工作负载:

* deployment 示例文件

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-app-deployment
spec:
  replicas: 3
  selector:
    matchLabels:
      app: my-app
  template:
    metadata:
      labels:
        app: my-app
    spec:
      containers:
        - name: my-app-container
          image: myregistry/my-app-image:latest
          ports:
            - containerPort: 80
```

### 2. 服务和服务发现：

* Service 文件示例

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-app-service
spec:
  selector:
    app: my-app
  ports:
    - protocol: TCP
      port: 80
      targetPort: 80
  type: ClusterIP
```

* IngressRoute 文件示例（使用 Traefik）：

```yaml
apiVersion: traefik.containo.us/v1alpha1
kind: IngressRoute
metadata:
  name: my-app-ingress
spec:
  entryPoints:
    - web
  routes:
    - match: Host(`example.com`) && PathPrefix(`/`)
      kind: Rule
      services:
        - name: my-app-service
          port: 80
```

### 3. 存储/配置：

#### 1.数据持久化实现

在创建储存类之前我们需要有一个网络储存服务器，我一般使用NFS,

使用以下命令安装NFS服务端：

```
apt update
apt install nfs-kernel-server
```

修改/etc/exports文件，编辑内容为：

`/root/nfs_root/ *(insecure,rw,sync,no_root_squash) `# 路径表示要共享的路径
使用以下命令启动NFS服务器：

```
#创建共享目录，如果要使用自己的目录，请替换所有的 /root/nfs_root/
mkdir /root/nfs_root

systemctl enable rpcbind
systemctl enable nfs-server

systemctl start rpcbind
systemctl start nfs-server
exportfs -r
#执行完成后使用以下命令检查配置结果：
exportfs
```

NFS存储卷的配置示例：

```
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: my-pvc
spec:
  storageClassName: my-storage-class
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 1Gi
```

#### 2.覆写command/args/entrypoint

在 Kubernetes 中，可以通过覆写容器的 `command`、`args`、`entrypoint` 字段来指定容器启动时要执行的命令和参数。这样可以在运行容器时动态地改变容器的默认行为。

1. 覆写 `command` 和 `args` 字段：

`command` 字段用于指定容器启动时要执行的命令，`args` 字段用于指定传递给命令的参数。如果没有指定 `command`，Kubernetes 将使用容器镜像中默认的启动命令。

例如，假设容器镜像的默认启动命令是 `/app/myapp`，但我们希望启动容器时执行 `/app/myapp --option value`：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      command: ["/app/myapp"]
      args: ["--option", "value"]
```

2. 覆写 `entrypoint` 字段：

`entrypoint` 字段用于指定容器启动时要执行的入口点（即启动脚本或可执行文件）。与 `command` 字段不同，`entrypoint` 字段指定的入口点不会被 `args` 参数所覆盖。`args` 参数将被附加到 `entrypoint` 参数之后。

例如，假设容器镜像的默认入口点是 `/app/entrypoint.sh`，但我们希望启动容器时执行 `/app/entrypoint.sh --option value`：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      entrypoint: ["/app/entrypoint.sh"]
      args: ["--option", "value"]
```

在上述示例中，`args` 参数将会附加到 `entrypoint` 指定的入口点之后，实际执行的命令是 `/app/entrypoint.sh --option value`。

请注意，覆写 `command`、`args` 或 `entrypoint` 字段时应确保镜像中指定的文件路径是正确的，并且需要根据您实际的容器镜像和运行需求做出相应的调整。

#### 3.向pod传入环境变量

向 Kubernetes 中的 Pod 传递环境变量有几种方法，可以通过在 Pod 的定义中直接指定环境变量，也可以通过 ConfigMap 或 Secret 来传递环境变量。

1. 直接在 Pod 定义中指定环境变量：

在 Pod 的 `spec` 下的 `containers` 字段中，可以使用 `env` 字段来指定环境变量。每个环境变量都包含一个 `name` 和一个 `value`。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      env:
        - name: ENV_VAR_NAME
          value: "value_of_env_var"
        - name: ANOTHER_ENV_VAR
          value: "another_value"
```

#### 4.configMap

##### 1.编写configMap的键值对配置文件

首先，创建一个 ConfigMap，其中包含环境变量的键值对。然后，在 Pod 的 `spec` 下的 `containers` 字段中使用 `envFrom` 来引用 ConfigMap 中的键值对作为环境变量。

```
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  ENV_VAR_NAME: value_of_env_var
  ANOTHER_ENV_VAR: another_value

---

apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      envFrom:
        - configMapRef:
            name: my-configmap
```



##### 2.使用configMap卷挂载

使用 ConfigMap 卷挂载是一种将 ConfigMap 中的数据以文件的形式挂载到容器中的方法。这样可以让容器访问 ConfigMap 中的配置数据。

以下是一个使用 ConfigMap 卷挂载的示例：

1. 首先，创建一个 ConfigMap，其中包含您要挂载到容器的配置数据：

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  app_config.ini: |
    key1=value1
    key2=value2
```

2. 创建一个 Pod，将 ConfigMap 中的数据以卷挂载到容器：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      volumeMounts:
        - name: config-volume
          mountPath: /etc/app-config
  volumes:
    - name: config-volume
      configMap:
        name: my-configmap
```

在上述示例中，我们创建了一个名为 `my-configmap` 的 ConfigMap，其中包含了一个名为 `app_config.ini` 的配置文件。然后，我们创建了一个 Pod，将 `my-configmap` 中的数据以卷的形式挂载到容器中的 `/etc/app-config` 目录。

这样，容器内部的 `/etc/app-config` 目录将包含 ConfigMap 中的 `app_config.ini` 文件，并可以通过文件系统进行访问。

使用 ConfigMap 卷挂载的好处是，当 ConfigMap 中的数据发生变化时，容器内部的文件也会相应地更新，而无需重启容器。这使得配置的动态更新变得很方便。

在 Kubernetes 中，使用 ConfigMap 或 Secret 卷挂载时，如果多个容器挂载相同的 ConfigMap 或 Secret 到相同的目录，可能会导致其中一个容器的配置文件覆盖其他容器的配置文件。为了避免这种情况，可以使用 `subPath` 字段来指定在容器中的不同路径下挂载 ConfigMap 或 Secret 中的不同文件，从而避免覆盖。

以下是使用 `subPath` 避免覆盖的示例：

假设有一个 ConfigMap 包含两个配置文件：`app_config.ini` 和 `db_config.ini`。

1. 创建 ConfigMap：

```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-configmap
data:
  app_config.ini: |
    key1=value1
    key2=value2
  db_config.ini: |
    db_host=example.com
    db_port=3306
```

2. 创建一个 Pod，将 ConfigMap 中的不同文件以不同的路径挂载到容器：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: app-container
      image: myregistry/app-image:latest
      volumeMounts:
        - name: app-config-volume
          mountPath: /etc/app-config
          subPath: app_config.ini
    - name: db-container
      image: myregistry/db-image:latest
      volumeMounts:
        - name: db-config-volume
          mountPath: /etc/db-config
          subPath: db_config.ini
  volumes:
    - name: app-config-volume
      configMap:
        name: my-configmap
    - name: db-config-volume
      configMap:
        name: my-configmap
```

在上述示例中，我们创建了一个名为 `my-configmap` 的 ConfigMap，其中包含了两个配置文件：`app_config.ini` 和 `db_config.ini`。然后，我们创建了一个 Pod，将 `app_config.ini` 以 `app-container` 的 `/etc/app-config` 目录挂载，将 `db_config.ini` 以 `db-container` 的 `/etc/db-config` 目录挂载。

这样，不同的容器可以在不同的路径下访问 ConfigMap 中的不同文件，避免了配置文件的覆盖。

使用 `subPath` 时需要注意，被挂载的路径必须是文件路径，而不是目录路径。因此，不能使用 `subPath` 来指定整个目录的挂载。如果需要挂载整个目录，可以考虑使用不同的 ConfigMap 或 Secret 来分别挂载到不同的目录下。

### 4.鉴权，安全 --secret

#### 1.secret类型

Kubernetes 中的 Secret 类型有三种常见的类型：Opaque Secret、dockerconfigjson 和 service-account-token。

1. Opaque Secret: Opaque Secret 是一种通用的 Secret 类型，可以用于存储任意类型的敏感数据，例如密码、API 密钥、证书等。这些敏感数据在存储到 Secret 中时需要进行 base64 编码，但在使用时需要进行解码。Opaque Secret 对数据的内容本身并不做特定的解析或处理，仅作为字节流存储。
2. dockerconfigjson: dockerconfigjson 是一种用于存储 Docker 镜像仓库认证信息的 Secret 类型。在使用私有 Docker 镜像仓库时，可能需要在 Kubernetes 中使用相应的凭据进行鉴权。dockerconfigjson 类型的 Secret 可以存储 Docker 镜像仓库的用户名、密码和仓库地址等认证信息。
3. service-account-token: service-account-token 是一种特殊的 Secret 类型，用于存储与 Kubernetes 服务账户相关的认证令牌。每个 Kubernetes Pod 都关联着一个服务账户，该服务账户对应的权限信息会存储在 service-account-token 类型的 Secret 中。这样，Pod 在与 Kubernetes API Server 进行交互时，可以使用相应的令牌来进行认证和授权。

#### 2.Secret创建方式

##### 1.使用kubectl创建

```
kubectl create secret docker-registry docker-myhub \
  --docker-server=<你的镜像仓库服务器> \
  --docker-username=<你的用户名> \
  --docker-password=<你的密码> \
  --docker-email=<你的邮箱地址>
```

##### 2.使用yaml创建

```
apiVersion: v1
kind: Secret
metadata:
  name: my-dockerhub-secret
  namespace: your-namespace  # 替换为您的命名空间
type: kubernetes.io/dockerconfigjson
data:
  .dockerconfigjson: <base64_encoded_docker_config>
```

在上面的 YAML 文件示例中，`<base64_encoded_docker_config>` 需要替换为您在 Docker Hub 上生成的认证信息，并进行 base64 编码。您可以通过以下方式获取 `docker_config.json` 的 base64 编码：

```
bashCopy code
cat ~/.docker/config.json | base64 -w0
```

将上述命令输出的结果填入到 YAML 文件中的 `<base64_encoded_docker_config>` 处。

#### 3.secret使用方式

在 Kubernetes 中，可以使用两种方式来使用 Secret：使用卷挂载方式和使用环境变量方式。

##### 1. 使用卷挂载方式：

使用卷挂载方式，可以将 Secret 中的数据以文件的形式挂载到容器中。这样容器就可以通过文件系统访问 Secret 中的敏感数据。

例如，假设有一个名为 `my-secret` 的 Secret，其中包含用户名和密码：

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      volumeMounts:
        - name: secret-volume
          mountPath: /etc/secrets
          readOnly: true
  volumes:
    - name: secret-volume
      secret:
        secretName: my-secret
```

在上述示例中，我们创建了一个 Pod，并将 `my-secret` 中的数据以卷挂载方式挂载到容器中的 `/etc/secrets` 目录。容器内部的 `/etc/secrets` 目录将包含 Secret 中的文件，例如 `username` 和 `password` 文件，容器可以通过该目录来访问这些敏感数据。

##### 2. 使用环境变量的方式：

使用环境变量的方式，可以将 Secret 中的数据以环境变量的形式注入到容器中。这样容器可以通过环境变量来获取敏感数据。

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-pod
spec:
  containers:
    - name: my-app-container
      image: myregistry/my-app-image:latest
      env:
        - name: USERNAME
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: username
        - name: PASSWORD
          valueFrom:
            secretKeyRef:
              name: my-secret
              key: password
```

在上述示例中，我们创建了一个 Pod，并使用环境变量的方式将 `my-secret` 中的 `username` 和 `password` 注入到容器中。容器可以通过环境变量 `USERNAME` 和 `PASSWORD` 来获取这些敏感数据。

使用哪种方式取决于需求和偏好。卷挂载方式适用于较大的敏感数据，如配置文件，而环境变量方式适用于较小的敏感数据，如密码或 API 密钥。请根据实际情况选择合适的方式来使用 Secret。

### 3.1.4.helm和helm chart

#### 1.使用helm安装一些集群应用

国外下载比较慢，使用国内华为镜像源下载

国外官方地址：https://github.com/helm/helm/releases

国内镜像地址：
Index of helm-local
https://mirrors.huaweicloud.com/helm/

添加国内源：

helm几个常用仓库：

helm官方：https://hub.helm.sh/

bitnami: https://charts.bitnami.com/bitnami

开源社是由中国支持开源的企业,社区及个人所组织的一个开源联盟,旨在推广开源。

开源社镜像：

http://mirror.kaiyuanshe.cn/kubernetes/charts/

http://mirror.azure.cn/kubernetes/charts/

kubernetes app商店：

https://hub.kubeapps.com/
```
# 查看当前配置的仓库地址
$ helm repo list
# 删除默认仓库，默认在国外pull很慢
$ helm repo remove stable
# 添加几个常用的仓库,可自定义名字
$ helm repo add stable https://kubernetes.oss-cn-hangzhou.aliyuncs.com/charts
$ helm repo add kaiyuanshe http://mirror.kaiyuanshe.cn/kubernetes/charts
$ helm repo add azure http://mirror.azure.cn/kubernetes/charts
$ helm repo add dandydev https://dandydeveloper.github.io/charts
$ helm repo add bitnami https://charts.bitnami.com/bitnami
# 搜索chart
$ helm search repo redis
# 拉取chart包到本地
$ helm pull bitnami/redis-cluster --version 8.1.2
# 安装redis-ha集群，取名redis-ha，需要指定持存储类
$ helm install redis-cluster bitnami/redis-cluster --set global.storageClass=nfs,global.redis.password=xiagao --version 8.1.2
# 卸载
$ helm uninstall redis-cluster
```

#### 2.编写helm chart

学会自己编写和设计 Helm Chart允许自定义和管理自己的 Kubernetes 应用程序。下面是一些编写 Helm Chart 的一般步骤：

##### 步骤 1：创建 Chart 目录结构

首先，您需要创建一个新的目录，用于存放您的 Chart。在该目录下，按照以下结构创建 Chart 的文件和目录：

```
my-chart/
  ├── charts/       # 可选：存放依赖的子 Chart
  ├── templates/    # 存放 Kubernetes 资源模板（Deployment、Service 等）
  ├── values.yaml   # 默认的配置值
  ├── Chart.yaml    # Chart 的元信息
  └── README.md     # Chart 的文档和说明（可选）
```

##### 步骤 2：编辑 Chart.yaml

在 `Chart.yaml` 文件中定义 Chart 的元信息，例如名称、版本、描述等。

```yaml
apiVersion: v2
name: my-chart
version: 1.0.0
description: A Helm Chart for my application
```

##### 步骤 3：编辑 values.yaml

在 `values.yaml` 文件中定义默认的配置值和参数。这些配置值将在模板文件中使用，并允许用户在安装 Chart 时自定义配置。

```yaml
# values.yaml
myApp:
  image: myregistry/my-app-image:latest
  port: 8080
```

##### 步骤 4：编写模板文件

在 `templates/` 目录中编写 Kubernetes 资源模板文件。使用 Go Template 语法，在模板文件中使用 `{{ .Values }}` 和其他 Helm 内置对象来插入值和配置。

```yaml
# templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: {{ .Release.Name }}-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: {{ .Release.Name }}
  template:
    metadata:
      labels:
        app: {{ .Release.Name }}
    spec:
      containers:
        - name: my-app-container
          image: {{ .Values.myApp.image }}
          ports:
            - containerPort: {{ .Values.myApp.port }}
```

##### 步骤 5：定义 Service 和其他资源

根据应用程序需要，定义其他 Kubernetes 资源（例如 Service、Ingress 等）。

##### 步骤 6：测试 Chart

在本地使用 Helm 安装 Chart 并测试其正确性：

```bash
helm install my-test ./my-chart
```

以上是创建 Helm Chart 的一般步骤。可以根据应用程序需求和配置选项，添加更多的模板文件和资源。请参考 Helm 官方文档（https://helm.sh/docs/chart_template_guide/）以获取更多详细信息和示例。

#### 3.通过自己编写设计的helm chart发布为应用并安装使用

发布自己编写设计的 Helm Chart 供他人使用可以通过以下步骤完成：

##### 步骤 1：准备 Chart

确保您的 Helm Chart 目录结构和模板文件已经准备好，并且可以正常在本地进行测试。

##### 步骤 2：打包 Chart

使用以下命令将 Helm Chart 打包成一个 tar 包：

```bash
helm package my-chart
```

上述命令将在当前目录下生成一个名为 `my-chart-1.0.0.tgz` 的 tar 包，其中 `1.0.0` 是 Chart 的版本号。

##### 步骤 3：创建 Helm 仓库

创建一个用于存放 Helm Chart 的仓库。您可以使用 GitHub Pages、AWS S3、Nginx 等方式创建一个可访问的 Web 服务器来作为 Helm 仓库。

##### 步骤 4：上传 Chart 包

将打包好的 Chart 包上传到 Helm 仓库，并确保 Chart 包可以通过仓库 URL 进行访问。

##### 步骤 5：添加 Helm 仓库

在使用 Chart 的用户端，需要添加您创建的 Helm 仓库到 Helm 中：

```bash
helm repo add my-repo <repository-url>
helm repo update
```

##### 步骤 6：安装 Chart

现在其他用户就可以通过 Helm 安装并使用您的 Chart 了：

```bash
helm install my-app my-repo/my-chart
```

上述命令会从您创建的 Helm 仓库中下载并安装 `my-chart`。

##### 步骤 7：升级和卸载

其他用户可以通过 Helm 来升级和卸载您的 Chart：

- 升级 Chart：
```bash
helm upgrade my-app my-repo/my-chart
```

- 卸载 Chart：
```bash
helm delete my-app
```

### 3.1.5. k8s集群管理

#### 1.kubeconfig：

外部获取集群权限,一般在

1. Linux 和 macOS：
   - 当前用户目录：~/.kube/config
2. Windows：
   - 当前用户目录：C:\Users<username>.kube\config

注意：上述路径中的 "<username>" 应该替换为你的用户名

可以用于runner等使用

#### 2.管理面板

##### 1.Dashboard

Kubernetes Dashboard 是 Kubernetes 官方提供的管理面板，它是一个基于 Web 的用户界面，可用于管理单个 Kubernetes 集群。通过 Dashboard，你可以查看集群中的节点、命名空间、Pod、服务、副本控制器等资源，以及执行一些常见的操作，如创建、删除和更新资源。Dashboard 还提供了一些监控和诊断功能，使得你可以查看集群的运行状态和性能指标。

##### 2.Kuboard

Kuboard（前身为 K8s Dashboard）是一个由开源社区开发的 Kubernetes 管理面板。它为 Kubernetes 提供了一个更加强大和丰富的用户界面，支持多集群管理，可以同时管理多个 Kubernetes 集群。Kuboard 提供了更多的可视化功能，如资源图谱、应用拓扑图、资源关系图等，使得集群管理和应用部署更加直观和便捷。Kuboard 也提供了更丰富的监控和告警功能，可以帮助你更好地了解和管理集群的运行状态。

##### 3.KubeSphere

KubeSphere 是一个基于 Kubernetes 和云原生技术栈构建的开源容器管理平台。它不仅提供了 Kubernetes 管理面板，还包括了多个扩展组件，如应用市场、DevOps 工具链、多租户管理等。KubeSphere 的目标是让 Kubernetes 在企业中更易用，它提供了更全面和集成的功能，适用于企业级的容器化应用开发和管理。

#### 3.集群用户权限配置

在 Kubernetes 中，集群用户权限配置是通过 RBAC（Role-Based Access Control，基于角色的访问控制）来实现的。RBAC 允许集群管理员定义不同角色和角色绑定，从而控制用户和服务账号对集群资源的访问权限。以下是配置集群用户权限的一般步骤：

1. **创建 RBAC 角色（Role）或集群角色（ClusterRole）**：
   - `Role`：用于在特定命名空间内定义权限。
   - `ClusterRole`：用于在整个集群范围内定义权限。

2. **定义 RBAC 角色绑定（RoleBinding）或集群角色绑定（ClusterRoleBinding）**：
   - `RoleBinding`：将角色授权给一个或多个用户或服务账号，并将其绑定到特定的命名空间。
   - `ClusterRoleBinding`：将集群角色授权给一个或多个用户或服务账号。

3. **创建 Kubernetes 用户或服务账号**：
   - Kubernetes 用户：由集群外的身份验证系统验证的用户。
   - 服务账号：用于代表 Pod 中的应用程序。

以下是一些示例来说明如何配置集群用户权限：

**示例 1 - 创建角色和绑定到用户**：

1. 创建一个 Role 对象，定义用户在特定命名空间中的权限：

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-role
  namespace: my-namespace
rules:
- apiGroups: [""]  # "" 表示核心 API 组
  resources: ["pods"]
  verbs: ["get", "list", "create", "delete"]
```

2. 创建 RoleBinding 对象，将 Role 授权给特定用户：

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-role-binding
  namespace: my-namespace
subjects:
- kind: User
  name: john  # 用户名
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: Role
  name: my-role
  apiGroup: rbac.authorization.k8s.io
```

**示例 2 - 创建集群角色和绑定到服务账号**：

1. 创建一个 ClusterRole 对象，定义集群范围内的权限：

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-cluster-role
rules:
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "update"]
```

2. 创建 ClusterRoleBinding 对象，将 ClusterRole 授权给特定服务账号：

```yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-cluster-role-binding
subjects:
- kind: ServiceAccount
  name: my-service-account
  namespace: my-namespace
roleRef:
  kind: ClusterRole
  name: my-cluster-role
  apiGroup: rbac.authorization.k8s.io
```

请注意，这些示例只是简化的例子，实际情况中需要根据你的需求和集群结构来定义合适的角色和绑定。确保在配置权限时按照最小权限原则，以确保安全性和资源隔离。

### 3.2.0集群配置

#### 3.2.1集群储存方案

##### 1.hostPath/emptyDir
   不应使用，不易管理

1. **hostPath**：
   - `hostPath` Volume 允许将主机（Node）上的文件或目录直接挂载到 Pod 中。这意味着 Pod 中的容器可以访问主机上的文件系统，以及其中的文件和目录。`hostPath` 是直接从主机上挂载数据，因此在不同的 Node 上使用相同的 `hostPath` 时，会导致数据不一致，也不适用于多节点的部署。
   - 使用 `hostPath` 时要谨慎，因为它可能导致数据冲突，并且可能破坏 Kubernetes 的资源隔离性。
2. **emptyDir**：
   - `emptyDir` Volume 是一个临时存储，只在 Pod 的生命周期内存在。它在 Pod 被调度到 Node 上时创建，并在 Pod 终止时被清理。这意味着 `emptyDir` Volume 不适合用于持久化存储，而主要用于在 Pod 中共享临时数据。
   - 由于 `emptyDir` 是在 Pod 内部创建的，它可以在同一 Pod 中的不同容器之间共享数据，这对于容器间的通信和共享临时数据非常有用。

综上所述，`hostPath` 适用于需要访问主机上文件系统的情况，但需要小心使用以避免潜在的问题。而 `emptyDir` 适用于在同一 Pod 中的容器之间共享临时数据，并且不适用于持久化存储。对于需要持久化存储的需求，应该考虑使用其他类型的持久化 Volume，如 `PersistentVolume` 和 `PersistentVolumeClaim`。

##### 2.分布式存储

Ceph 是一个开源的分布式存储系统，它提供了多种存储类型以满足不同的应用场景。以下是 Ceph 分布式存储的三种主要存储类型，以及它们的区别和应用场景：

1. **块存储 (RBD - RADOS Block Device)**:
   - 块存储是 Ceph 的一种存储类型，它提供了类似于传统硬盘的块设备接口，允许将块设备挂载到主机上。每个块设备都是分布式存储集群中的一个 RBD 映像，它可以被多个主机挂载和共享，形成共享块存储池。
   - 应用场景：块存储通常用于需要低延迟和高性能的应用，如数据库、虚拟机镜像、容器存储等。它对于那些需要使用传统块设备接口的应用程序非常有用，同时提供了高度可扩展性和容错性。

2. **文件系统存储 (CephFS)**:
   - CephFS 是 Ceph 提供的分布式文件系统，它允许在多个主机之间共享文件。CephFS 使用了统一的命名空间，并在整个 Ceph 存储集群上存储文件和目录数据，因此可以被多个主机挂载，并实现共享文件系统的功能。
   - 应用场景：CephFS 适用于需要共享文件系统的应用场景，如容器编排系统中的多个 Pod 需要访问共享存储，或者需要在多个主机之间共享配置文件和日志等数据。

3. **对象存储 (RGW - RADOS Gateway)**:
   - 对象存储是 Ceph 的另一种存储类型，通过 RGW 提供了 RESTful API 来管理和存储数据。对象存储以对象的形式存储数据，并使用唯一的键标识对象，可以在整个 Ceph 存储集群中进行分布式存储和访问。
   - 应用场景：对象存储非常适合存储海量的非结构化数据，如图像、视频、日志文件、备份数据等。它在云存储、大数据分析和备份恢复等场景中得到广泛应用。

综上所述，Ceph 提供了多种存储类型以满足不同的应用场景。块存储 (RBD) 适用于需要高性能和低延迟的应用；文件系统存储 (CephFS) 适用于需要共享文件系统的场景；对象存储 (RGW) 适用于海量的非结构化数据存储需求。根据具体的应用需求，你可以选择适合的 Ceph 存储类型来搭建分布式存储系统。

### 4.0.0.运维开发

#### 4.1.0.git规范

参考[约定式提交 (conventionalcommits.org)](https://www.conventionalcommits.org/zh-hans/v1.0.0/)

#### 4.2.0开发规范

开发规范、设计模式、JWT（JSON Web Token）和中间件都是软件开发中重要的概念和工具，它们有助于提高代码质量、可维护性和安全性。

1. **开发规范**：
   开发规范是指在软件开发过程中制定的一系列规则和标准，以确保团队成员之间的代码风格一致，并提高代码的可读性和可维护性。开发规范通常包括代码格式化、命名规则、注释规范、代码组织结构等内容。遵循良好的开发规范可以减少错误、加快开发速度，并方便新成员快速融入项目。

2. **设计模式**：
   设计模式是一种在软件设计中经常出现的解决问题的方案。它们是被广泛认可和验证的，可以帮助开发人员解决常见的设计问题，并提高代码的可扩展性和复用性。常见的设计模式包括单例模式、工厂模式、观察者模式、策略模式等。了解和应用设计模式可以使开发人员写出更优雅、更灵活的代码。

3. **JWT（JSON Web Token）**：
   JWT 是一种用于安全通信的开放标准，它定义了一种紧凑且自包含的方式来在两个实体之间传递信息。JWT 主要用于在客户端和服务器之间进行身份认证和授权。JWT 通常包含了一些声明（Claims），例如用户身份、角色、权限等信息，使用密钥进行签名，以确保数据的完整性和安全性。

4. **中间件**：
   中间件是指位于客户端和服务器之间的软件组件，用于在处理请求和响应过程中添加额外的功能或逻辑。中间件可以用于日志记录、身份验证、缓存、压缩、错误处理等。在很多 Web 框架中，中间件是一种模块化的方式来处理请求和响应，通过链式调用的方式，依次经过多个中间件的处理。

综上所述，开发规范和设计模式帮助开发人员写出高质量、可维护的代码，JWT 提供了一种安全通信的标准，中间件可以增强应用的功能和可扩展性。在实际的软件开发过程中，合理应用这些概念和工具将有助于提高开发效率和代码质量。

### 4.3.0.gitlab和CI/CD

#### 1.配置runner

使用docker来安装runner

```shell
docker run -d --name gitlab-runner --restart always \
  -v /srv/gitlab-runner/config:/etc/gitlab-runner \
  -v /var/run/docker.sock:/var/run/docker.sock \
  gitlab/gitlab-runner:latest
```

- 注册

  ```
  docker exec -it gitlab-runner bash
  ```

  ```
  gitlab-runner register \
  --non-interactive \
  --url "https://gitlab.com/" \
  --registration-token "你在gitlab上runner的注册码" \
  --executor "docker" \
  --docker-image ubuntu:22.04 \
  --description "docker-runner" \
  --tag-list "docker" \
  --run-untagged="true" \
  --locked="false" \
  --access-level="not_protected"
  ```

  注意:记得关闭shared runner选项

- 使用如下的方式可以查看runner的日志

  ```
  docker logs gitlab-runner
  ```

  #### 2.编写yaml脚本来运行CI项目

编写 YAML 脚本来运行 CI（持续集成）项目通常是通过 CI/CD 工具来实现的，比如 Jenkins、GitLab CI、Travis CI 等。不同的 CI/CD 工具可能有不同的 YAML 配置语法和配置项，下面我将以 GitLab CI 为例，演示一个简单的 YAML 脚本来运行 CI 项目。

在 GitLab CI 中，CI 任务的配置文件通常被称为 `.gitlab-ci.yml`，它位于项目的根目录下。以下是一个简单的示例 `.gitlab-ci.yml` 文件：

```
stages:
  - build
  - deploy
variables:
  DOCKER_AUTH_CONFIG: '{"auths": {"registry.xxxxxx.com": {"auth": "xxxxxxxx"}}}'
imagebuilder:
  image: ${DOCKER_REGISTRY}/ferdina/kaniko:v2
  stage: build
  variables:
    destination: ${DOCKER_REGISTRY}/ferdina/project-golang:v6
  script:
    - /kaniko/build-upload

deploy:
  image: 
    name: bitnami/kubectl
    entrypoint: [""]
  stage: deploy
  script:
    - kubectl apply -f ./test.yaml --kubeconfig=./kubeconfig.yaml
    - kubectl apply -f ./service.yaml --kubeconfig=./kubeconfig.yaml

```

以上是一个向私人仓库运行CI项目的实例，docker_auth_config一般在$HOME/.docker/config.json

#### 项目信息脱敏

- 在设置中配置私密变量

![image-20230806164455558](https://gitee.com/ferdinandaedth/ferdinand/raw/master/image-20230806164455558.png)
